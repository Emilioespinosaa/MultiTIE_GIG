{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Model Training and Evaluation\n",
    "This notebook contains training and evaluation of machine learning models for regression.\n",
    "\n",
    "## Models to evaluate:\n",
    "1. **Multivariate Linear Regression** (LinearRegression)\n",
    "2. **Support Vector Regression (SVR)**\n",
    "3. **XGBoost Regressor**\n",
    "\n",
    "## Objectives:\n",
    "- Train models with different hyperparameters\n",
    "- Evaluate performance with regression metrics\n",
    "- Analyze feature importance\n",
    "- Compare models and select the best one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, validation_curve\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
    "from sklearn.inspection import permutation_importance\n",
    "#import xgboost as xgb\n",
    "from scipy import stats\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '../cloud-data/its-cmo-darwin-magellan-workspaces-folders/WS_PMCB/BisCiT_Repository/results/current_version/v2.0c/aa/dtl-surfaceome-secretome-equal_0.1/results-with-evidence-full.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully: 11943461 rows and 19 columns\n"
     ]
    }
   ],
   "source": [
    "file_path = dataset_path\n",
    "\n",
    "df = pd.read_csv(file_path, sep='\\t')\n",
    "print(f\"Dataset loaded successfully: {df.shape[0]} rows and {df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gene 1</th>\n",
       "      <th>Gene 2</th>\n",
       "      <th>AA Score</th>\n",
       "      <th>Genetics</th>\n",
       "      <th>Knowledge Graph Connectivity</th>\n",
       "      <th>Single Cell DE</th>\n",
       "      <th>Single Cell Expression</th>\n",
       "      <th>Single Cell Specificity</th>\n",
       "      <th>Ligand Receptor Significance</th>\n",
       "      <th>SC KO, positive</th>\n",
       "      <th>Credentialing</th>\n",
       "      <th>Credentialing bulk RNA</th>\n",
       "      <th>SC KO, Negative</th>\n",
       "      <th>DTL, Th1-17</th>\n",
       "      <th>DTL, Th2</th>\n",
       "      <th>Immune Competition</th>\n",
       "      <th>Single Cell Co-dysregulation, positive</th>\n",
       "      <th>Single Cell Co-dysregulation, negative</th>\n",
       "      <th>Single Cell Co-dysregulation, mixed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CTLA4</td>\n",
       "      <td>IL2RA</td>\n",
       "      <td>3.750244</td>\n",
       "      <td>0.850673</td>\n",
       "      <td>0.932113</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.266357</td>\n",
       "      <td>0.230324</td>\n",
       "      <td>0.363851</td>\n",
       "      <td>0.157781</td>\n",
       "      <td>0.952958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.003812</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IL2RA</td>\n",
       "      <td>TNFRSF1A</td>\n",
       "      <td>3.516827</td>\n",
       "      <td>0.723262</td>\n",
       "      <td>0.741249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.334782</td>\n",
       "      <td>0.177688</td>\n",
       "      <td>0.462156</td>\n",
       "      <td>0.480434</td>\n",
       "      <td>0.669561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.072305</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Gene 1    Gene 2  AA Score  Genetics  Knowledge Graph Connectivity  \\\n",
       "0  CTLA4     IL2RA  3.750244  0.850673                      0.932113   \n",
       "1  IL2RA  TNFRSF1A  3.516827  0.723262                      0.741249   \n",
       "\n",
       "   Single Cell DE  Single Cell Expression  Single Cell Specificity  \\\n",
       "0             0.0                0.266357                 0.230324   \n",
       "1             0.0                0.334782                 0.177688   \n",
       "\n",
       "   Ligand Receptor Significance  SC KO, positive  Credentialing  \\\n",
       "0                      0.363851         0.157781       0.952958   \n",
       "1                      0.462156         0.480434       0.669561   \n",
       "\n",
       "   Credentialing bulk RNA  SC KO, Negative  DTL, Th1-17  DTL, Th2  \\\n",
       "0                     0.0        -0.003812          NaN       NaN   \n",
       "1                     0.0        -0.072305          NaN       NaN   \n",
       "\n",
       "   Immune Competition  Single Cell Co-dysregulation, positive  \\\n",
       "0                 0.0                                     0.0   \n",
       "1                 0.0                                     0.0   \n",
       "\n",
       "   Single Cell Co-dysregulation, negative  Single Cell Co-dysregulation, mixed  \n",
       "0                                     0.0                                  0.0  \n",
       "1                                     0.0                                  0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Gene 1', 'Gene 2', 'AA Score', 'Genetics',\n",
       "       'Knowledge Graph Connectivity', 'Single Cell DE',\n",
       "       'Single Cell Expression', 'Single Cell Specificity',\n",
       "       'Ligand Receptor Significance', 'SC KO, positive', 'Credentialing',\n",
       "       'Credentialing bulk RNA', 'SC KO, Negative', 'DTL, Th1-17', 'DTL, Th2',\n",
       "       'Immune Competition', 'Single Cell Co-dysregulation, positive',\n",
       "       'Single Cell Co-dysregulation, negative',\n",
       "       'Single Cell Co-dysregulation, mixed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection of features and target columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_columns = ['Genetics',\n",
    "       'Knowledge Graph Connectivity', 'Single Cell DE',\n",
    "       'Single Cell Expression', 'Single Cell Specificity',\n",
    "       'Ligand Receptor Significance', 'SC KO, positive', 'Credentialing',\n",
    "       'Credentialing bulk RNA', 'SC KO, Negative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: ['Genetics', 'Knowledge Graph Connectivity', 'Single Cell DE', 'Single Cell Expression', 'Single Cell Specificity', 'Ligand Receptor Significance', 'SC KO, positive', 'Credentialing', 'Credentialing bulk RNA', 'SC KO, Negative']\n",
      "X shape: (11943461, 10)\n",
      "y shape: (11943461,)\n",
      "\n",
      "Missing values in X: 0\n",
      "Missing values in y: 0\n"
     ]
    }
   ],
   "source": [
    "# Data preparation\n",
    "# Separate features and target variable\n",
    "feature_cols = [col for col in features_columns]\n",
    "X = df[feature_cols]\n",
    "y = df['AA Score']\n",
    "\n",
    "print(f\"Selected features: {feature_cols}\")\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "\n",
    "# Check for missing values\n",
    "missing_X = X.isnull().sum().sum()\n",
    "missing_y = y.isnull().sum()\n",
    "print(f\"\\nMissing values in X: {missing_X}\")\n",
    "print(f\"Missing values in y: {missing_y}\")\n",
    "\n",
    "# Remove rows with missing values if they exist\n",
    "if missing_X > 0 or missing_y > 0:\n",
    "    mask = ~(X.isnull().any(axis=1) | y.isnull())\n",
    "    X = X[mask]\n",
    "    y = y[mask]\n",
    "    print(f\"After cleaning data: X={X.shape}, y={y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 9554768 samples\n",
      "Test set: 2388693 samples\n",
      "Train/test ratio: 4.0\n",
      "\n",
      "Target variable statistics:\n",
      "Train - Mean: 0.22, Std: 0.24\n",
      "Test  - Mean: 0.22, Std: 0.24\n"
     ]
    }
   ],
   "source": [
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=None\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"Train/test ratio: {X_train.shape[0]/X_test.shape[0]:.1f}\")\n",
    "\n",
    "# Target variable statistics\n",
    "print(f\"\\nTarget variable statistics:\")\n",
    "print(f\"Train - Mean: {y_train.mean():.2f}, Std: {y_train.std():.2f}\")\n",
    "print(f\"Test  - Mean: {y_test.mean():.2f}, Std: {y_test.std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scalers prepared:\n",
      "  ‚Ä¢ StandardScaler\n",
      "  ‚Ä¢ RobustScaler\n",
      "  ‚Ä¢ NoScaler\n"
     ]
    }
   ],
   "source": [
    "# Prepare different scalers\n",
    "scalers = {\n",
    "    'StandardScaler': StandardScaler(),\n",
    "    'RobustScaler': RobustScaler(),\n",
    "    'NoScaler': None\n",
    "}\n",
    "\n",
    "# Function to apply scaling\n",
    "def apply_scaling(scaler, X_train, X_test):\n",
    "    if scaler is None:\n",
    "        return X_train, X_test\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    return X_train_scaled, X_test_scaled\n",
    "\n",
    "print(\"Scalers prepared:\")\n",
    "for name in scalers.keys():\n",
    "    print(f\"  ‚Ä¢ {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluation Metrics Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics functions defined\n"
     ]
    }
   ],
   "source": [
    "def calculate_metrics(y_true, y_pred):\n",
    "    \"\"\"Calculate multiple regression metrics\"\"\"\n",
    "    metrics = {\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "        'MAE': mean_absolute_error(y_true, y_pred),\n",
    "        'R¬≤': r2_score(y_true, y_pred),\n",
    "        'MAPE': mean_absolute_percentage_error(y_true, y_pred) * 100,\n",
    "        'Adjusted_R¬≤': 1 - (1 - r2_score(y_true, y_pred)) * (len(y_true) - 1) / (len(y_true) - X_train.shape[1] - 1)\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "def print_metrics(metrics, title=\"Metrics\"):\n",
    "    \"\"\"Print metrics in organized format\"\"\"\n",
    "    print(f\"\\n=== {title} ===\")\n",
    "    for metric, value in metrics.items():\n",
    "        if metric in ['R¬≤', 'Adjusted_R¬≤']:\n",
    "            print(f\"{metric}: {value:.4f}\")\n",
    "        elif metric == 'MAPE':\n",
    "            print(f\"{metric}: {value:.2f}%\")\n",
    "        else:\n",
    "            print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "print(\"Metrics functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model 1: Linear Regression with Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç TRAINING LINEAR REGRESSION MODELS\n",
      "\n",
      "üîß Training LinearRegression...\n",
      "\n",
      "=== Training ===\n",
      "RMSE: 0.0000\n",
      "MAE: 0.0000\n",
      "R¬≤: 1.0000\n",
      "MAPE: 0.00%\n",
      "Adjusted_R¬≤: 1.0000\n",
      "\n",
      "=== Test ===\n",
      "RMSE: 0.0000\n",
      "MAE: 0.0000\n",
      "R¬≤: 1.0000\n",
      "MAPE: 0.00%\n",
      "Adjusted_R¬≤: 1.0000\n",
      "CV RMSE: 0.0000 (¬±0.0000)\n",
      "\n",
      "üîß Training Ridge...\n",
      "  Best hyperparameters: {'alpha': 0.1}\n",
      "\n",
      "=== Training ===\n",
      "RMSE: 0.0000\n",
      "MAE: 0.0000\n",
      "R¬≤: 1.0000\n",
      "MAPE: 289.79%\n",
      "Adjusted_R¬≤: 1.0000\n",
      "\n",
      "=== Test ===\n",
      "RMSE: 0.0000\n",
      "MAE: 0.0000\n",
      "R¬≤: 1.0000\n",
      "MAPE: 285.23%\n",
      "Adjusted_R¬≤: 1.0000\n",
      "CV RMSE: 0.0000 (¬±0.0000)\n",
      "\n",
      "üîß Training Lasso...\n",
      "  Best hyperparameters: {'alpha': 0.001}\n",
      "\n",
      "=== Training ===\n",
      "RMSE: 0.0564\n",
      "MAE: 0.0386\n",
      "R¬≤: 0.9435\n",
      "MAPE: 24105640.33%\n",
      "Adjusted_R¬≤: 0.9435\n",
      "\n",
      "=== Test ===\n",
      "RMSE: 0.0565\n",
      "MAE: 0.0386\n",
      "R¬≤: 0.9434\n",
      "MAPE: 23726757.01%\n",
      "Adjusted_R¬≤: 0.9434\n",
      "CV RMSE: 0.0564 (¬±0.0037)\n",
      "\n",
      "üîß Training ElasticNet...\n",
      "  Best hyperparameters: {'alpha': 0.001, 'l1_ratio': 0.1}\n",
      "\n",
      "=== Training ===\n",
      "RMSE: 0.0391\n",
      "MAE: 0.0274\n",
      "R¬≤: 0.9728\n",
      "MAPE: 18765079.42%\n",
      "Adjusted_R¬≤: 0.9728\n",
      "\n",
      "=== Test ===\n",
      "RMSE: 0.0392\n",
      "MAE: 0.0274\n",
      "R¬≤: 0.9728\n",
      "MAPE: 18470137.09%\n",
      "Adjusted_R¬≤: 0.9728\n",
      "CV RMSE: 0.0391 (¬±0.0024)\n",
      "\n",
      "‚úÖ Linear models trained successfully\n"
     ]
    }
   ],
   "source": [
    "print(\"üîç TRAINING LINEAR REGRESSION MODELS\")\n",
    "\n",
    "# Linear regression models to test\n",
    "linear_models = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'Ridge': Ridge(),\n",
    "    'Lasso': Lasso(max_iter=2000),\n",
    "    'ElasticNet': ElasticNet(max_iter=2000)\n",
    "}\n",
    "\n",
    "# Hyperparameters for search\n",
    "linear_params = {\n",
    "    'Ridge': {'alpha': [0.1, 1, 10, 100, 1000]},\n",
    "    'Lasso': {'alpha': [0.001, 0.01, 0.1, 1, 10]},\n",
    "    'ElasticNet': {\n",
    "        'alpha': [0.001, 0.01, 0.1, 1],\n",
    "        'l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Linear model results\n",
    "linear_results = {}\n",
    "\n",
    "# Use StandardScaler for linear models\n",
    "scaler = StandardScaler()\n",
    "#X_train_scaled, X_test_scaled = apply_scaling(scaler, X_train, X_test)\n",
    "X_train_scaled, X_test_scaled = X_train, X_test\n",
    "\n",
    "for model_name, model in linear_models.items():\n",
    "    print(f\"\\nüîß Training {model_name}...\")\n",
    "    \n",
    "    if model_name in linear_params:\n",
    "        # Hyperparameter search with cross-validation\n",
    "        grid_search = GridSearchCV(\n",
    "            model, linear_params[model_name], \n",
    "            cv=5, scoring='neg_mean_squared_error', \n",
    "            n_jobs=-1\n",
    "        )\n",
    "        grid_search.fit(X_train_scaled, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        print(f\"  Best hyperparameters: {grid_search.best_params_}\")\n",
    "    else:\n",
    "        # Model without hyperparameters\n",
    "        best_model = model\n",
    "        best_model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_train_pred = best_model.predict(X_train_scaled)\n",
    "    y_test_pred = best_model.predict(X_test_scaled)\n",
    "    \n",
    "    # Metrics\n",
    "    train_metrics = calculate_metrics(y_train, y_train_pred)\n",
    "    test_metrics = calculate_metrics(y_test, y_test_pred)\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(best_model, X_train_scaled, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    cv_rmse = np.sqrt(-cv_scores.mean())\n",
    "    cv_rmse_std = np.sqrt(cv_scores.std())\n",
    "    \n",
    "    linear_results[model_name] = {\n",
    "        'model': best_model,\n",
    "        'train_metrics': train_metrics,\n",
    "        'test_metrics': test_metrics,\n",
    "        'cv_rmse': cv_rmse,\n",
    "        'cv_rmse_std': cv_rmse_std,\n",
    "        'predictions': {'train': y_train_pred, 'test': y_test_pred}\n",
    "    }\n",
    "    \n",
    "    print_metrics(train_metrics, \"Training\")\n",
    "    print_metrics(test_metrics, \"Test\")\n",
    "    print(f\"CV RMSE: {cv_rmse:.4f} (¬±{cv_rmse_std:.4f})\")\n",
    "\n",
    "print(\"\\n‚úÖ Linear models trained successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model 2: Support Vector Regression (SVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç TRAINING SUPPORT VECTOR REGRESSION\n",
      "\n",
      "üîß Training SVR with linear kernel...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-a16176c76f15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m     )\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_robust\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mbest_svr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/local/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/local/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/local/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    849\u001b[0m                     )\n\u001b[1;32m    850\u001b[0m                     for (cand_idx, parameters), (split_idx, (train, test)) in product(\n\u001b[0;32m--> 851\u001b[0;31m                         \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m                     )\n\u001b[1;32m    853\u001b[0m                 )\n",
      "\u001b[0;32m/opt/local/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1862\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1863\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1865\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/local/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1791\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1792\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1793\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/local/anaconda3/lib/python3.7/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/local/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/local/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"i\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/local/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m             \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_seed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m         )\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msklearn/svm/_libsvm.pyx\u001b[0m in \u001b[0;36msklearn.svm._libsvm.fit\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"üîç TRAINING SUPPORT VECTOR REGRESSION\")\n",
    "\n",
    "# Hyperparameters for SVR\n",
    "svr_params = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'epsilon': [0.01, 0.1]\n",
    "}\n",
    "\n",
    "# Different kernels to test\n",
    "svr_kernels = ['linear', 'rbf', 'poly']\n",
    "svr_results = {}\n",
    "\n",
    "# Use RobustScaler for SVR (more robust to outliers)\n",
    "robust_scaler = RobustScaler()\n",
    "#X_train_robust, X_test_robust = apply_scaling(robust_scaler, X_train, X_test)\n",
    "\n",
    "X_train_robust, X_test_robust = X_train, X_test\n",
    "\n",
    "for kernel in svr_kernels:\n",
    "    print(f\"\\nüîß Training SVR with {kernel} kernel...\")\n",
    "    \n",
    "    # Create SVR model\n",
    "    svr_model = SVR(kernel=kernel)\n",
    "    \n",
    "    # Adjust parameters according to kernel\n",
    "    current_params = svr_params.copy()\n",
    "    if kernel == 'linear':\n",
    "        current_params.pop('gamma')  # Gamma not relevant for linear kernel\n",
    "    elif kernel == 'poly':\n",
    "        current_params['degree'] = [2, 3, 4]  # Add degree for polynomial\n",
    "    \n",
    "    # Hyperparameter search\n",
    "    grid_search = GridSearchCV(\n",
    "        svr_model, current_params, \n",
    "        cv=5, scoring='neg_mean_squared_error', \n",
    "        n_jobs=1, verbose=0\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_train_robust, y_train)\n",
    "    best_svr = grid_search.best_estimator_\n",
    "    \n",
    "    print(f\"  Best hyperparameters: {grid_search.best_params_}\")\n",
    "    \n",
    "    # Predictions\n",
    "    y_train_pred = best_svr.predict(X_train_robust)\n",
    "    y_test_pred = best_svr.predict(X_test_robust)\n",
    "    \n",
    "    # Metrics\n",
    "    train_metrics = calculate_metrics(y_train, y_train_pred)\n",
    "    test_metrics = calculate_metrics(y_test, y_test_pred)\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(best_svr, X_train_robust, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    cv_rmse = np.sqrt(-cv_scores.mean())\n",
    "    cv_rmse_std = np.sqrt(cv_scores.std())\n",
    "    \n",
    "    svr_results[f'SVR_{kernel}'] = {\n",
    "        'model': best_svr,\n",
    "        'train_metrics': train_metrics,\n",
    "        'test_metrics': test_metrics,\n",
    "        'cv_rmse': cv_rmse,\n",
    "        'cv_rmse_std': cv_rmse_std,\n",
    "        'predictions': {'train': y_train_pred, 'test': y_test_pred}\n",
    "    }\n",
    "    \n",
    "    print_metrics(train_metrics, \"Training\")\n",
    "    print_metrics(test_metrics, \"Test\")\n",
    "    print(f\"CV RMSE: {cv_rmse:.4f} (¬±{cv_rmse_std:.4f})\")\n",
    "\n",
    "print(\"\\n‚úÖ SVR models trained successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model 3: XGBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîç TRAINING XGBOOST REGRESSOR\")\n",
    "\n",
    "# Hyperparameters for XGBoost\n",
    "xgb_params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 4, 5, 6],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "# Create XGBoost model\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    random_state=42,\n",
    "    verbosity=0,\n",
    "    eval_metric='rmse'\n",
    ")\n",
    "\n",
    "# XGBoost doesn't require scaling, use original data\n",
    "print(\"üîß Training XGBoost (may take several minutes)...\")\n",
    "\n",
    "# Random search to reduce computation time\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Use RandomizedSearchCV instead of GridSearchCV for efficiency\n",
    "random_search = RandomizedSearchCV(\n",
    "    xgb_model, xgb_params,\n",
    "    n_iter=50,  # Number of combinations to test\n",
    "    cv=5, scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1, random_state=42,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "best_xgb = random_search.best_estimator_\n",
    "\n",
    "print(f\"  Best hyperparameters: {random_search.best_params_}\")\n",
    "\n",
    "# Predictions\n",
    "y_train_pred = best_xgb.predict(X_train)\n",
    "y_test_pred = best_xgb.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "train_metrics = calculate_metrics(y_train, y_train_pred)\n",
    "test_metrics = calculate_metrics(y_test, y_test_pred)\n",
    "\n",
    "# Cross-validation\n",
    "cv_scores = cross_val_score(best_xgb, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "cv_rmse = np.sqrt(-cv_scores.mean())\n",
    "cv_rmse_std = np.sqrt(cv_scores.std())\n",
    "\n",
    "xgb_results = {\n",
    "    'model': best_xgb,\n",
    "    'train_metrics': train_metrics,\n",
    "    'test_metrics': test_metrics,\n",
    "    'cv_rmse': cv_rmse,\n",
    "    'cv_rmse_std': cv_rmse_std,\n",
    "    'predictions': {'train': y_train_pred, 'test': y_test_pred}\n",
    "}\n",
    "\n",
    "print_metrics(train_metrics, \"Training\")\n",
    "print_metrics(test_metrics, \"Test\")\n",
    "print(f\"CV RMSE: {cv_rmse:.4f} (¬±{cv_rmse_std:.4f})\")\n",
    "\n",
    "print(\"\\n‚úÖ XGBoost model trained successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MODEL COMPARISON ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train_RMSE</th>\n",
       "      <th>Test_RMSE</th>\n",
       "      <th>Train_R¬≤</th>\n",
       "      <th>Test_R¬≤</th>\n",
       "      <th>Train_MAE</th>\n",
       "      <th>Test_MAE</th>\n",
       "      <th>CV_RMSE</th>\n",
       "      <th>CV_RMSE_Std</th>\n",
       "      <th>Overfitting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.0391</td>\n",
       "      <td>0.0392</td>\n",
       "      <td>0.9728</td>\n",
       "      <td>0.9728</td>\n",
       "      <td>0.0274</td>\n",
       "      <td>0.0274</td>\n",
       "      <td>0.0391</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>-0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.0564</td>\n",
       "      <td>0.0565</td>\n",
       "      <td>0.9435</td>\n",
       "      <td>0.9434</td>\n",
       "      <td>0.0386</td>\n",
       "      <td>0.0386</td>\n",
       "      <td>0.0564</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>-0.0001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model  Train_RMSE  Test_RMSE  Train_R¬≤  Test_R¬≤  Train_MAE  \\\n",
       "0  LinearRegression      0.0000     0.0000    1.0000   1.0000     0.0000   \n",
       "1             Ridge      0.0000     0.0000    1.0000   1.0000     0.0000   \n",
       "3        ElasticNet      0.0391     0.0392    0.9728   0.9728     0.0274   \n",
       "2             Lasso      0.0564     0.0565    0.9435   0.9434     0.0386   \n",
       "\n",
       "   Test_MAE  CV_RMSE  CV_RMSE_Std  Overfitting  \n",
       "0    0.0000   0.0000       0.0000      -0.0000  \n",
       "1    0.0000   0.0000       0.0000      -0.0000  \n",
       "3    0.0274   0.0391       0.0024      -0.0001  \n",
       "2    0.0386   0.0564       0.0037      -0.0001  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÜ BEST MODEL: LinearRegression\n",
      "   Test R¬≤: 1.0000\n",
      "   Test RMSE: 0.0000\n",
      "   CV RMSE: 0.0000 (¬±0.0000)\n"
     ]
    }
   ],
   "source": [
    "# Combine all results\n",
    "#all_results = {**linear_results, **svr_results, 'XGBoost': xgb_results}\n",
    "all_results = {**linear_results}\n",
    "\n",
    "# Create comparison DataFrame\n",
    "comparison_data = []\n",
    "for model_name, results in all_results.items():\n",
    "    comparison_data.append({\n",
    "        'Model': model_name,\n",
    "        'Train_RMSE': results['train_metrics']['RMSE'],\n",
    "        'Test_RMSE': results['test_metrics']['RMSE'],\n",
    "        'Train_R¬≤': results['train_metrics']['R¬≤'],\n",
    "        'Test_R¬≤': results['test_metrics']['R¬≤'],\n",
    "        'Train_MAE': results['train_metrics']['MAE'],\n",
    "        'Test_MAE': results['test_metrics']['MAE'],\n",
    "        'CV_RMSE': results['cv_rmse'],\n",
    "        'CV_RMSE_Std': results['cv_rmse_std'],\n",
    "        'Overfitting': results['train_metrics']['RMSE'] - results['test_metrics']['RMSE']\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "comparison_df = comparison_df.sort_values('Test_R¬≤', ascending=False)\n",
    "\n",
    "print(\"=== MODEL COMPARISON ===\")\n",
    "display(comparison_df.round(4))\n",
    "\n",
    "# Identify best model\n",
    "best_model_name = comparison_df.iloc[0]['Model']\n",
    "print(f\"\\nüèÜ BEST MODEL: {best_model_name}\")\n",
    "print(f\"   Test R¬≤: {comparison_df.iloc[0]['Test_R¬≤']:.4f}\")\n",
    "print(f\"   Test RMSE: {comparison_df.iloc[0]['Test_RMSE']:.4f}\")\n",
    "print(f\"   CV RMSE: {comparison_df.iloc[0]['CV_RMSE']:.4f} (¬±{comparison_df.iloc[0]['CV_RMSE_Std']:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x864 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model comparison visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# R¬≤ Score\n",
    "ax1 = axes[0, 0]\n",
    "x_pos = np.arange(len(comparison_df))\n",
    "ax1.bar(x_pos, comparison_df['Test_R¬≤'], alpha=0.7, color='lightblue')\n",
    "ax1.set_xlabel('Models')\n",
    "ax1.set_ylabel('R¬≤ Score')\n",
    "ax1.set_title('R¬≤ Score on Test Set')\n",
    "ax1.set_xticks(x_pos)\n",
    "ax1.set_xticklabels(comparison_df['Model'], rotation=45)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# RMSE\n",
    "ax2 = axes[0, 1]\n",
    "ax2.bar(x_pos, comparison_df['Test_RMSE'], alpha=0.7, color='lightcoral')\n",
    "ax2.set_xlabel('Models')\n",
    "ax2.set_ylabel('RMSE')\n",
    "ax2.set_title('RMSE on Test Set')\n",
    "ax2.set_xticks(x_pos)\n",
    "ax2.set_xticklabels(comparison_df['Model'], rotation=45)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Overfitting (Train RMSE - Test RMSE)\n",
    "ax3 = axes[1, 0]\n",
    "colors = ['red' if x > 0 else 'green' for x in comparison_df['Overfitting']]\n",
    "ax3.bar(x_pos, comparison_df['Overfitting'], alpha=0.7, color=colors)\n",
    "ax3.set_xlabel('Models')\n",
    "ax3.set_ylabel('Overfitting (Train RMSE - Test RMSE)')\n",
    "ax3.set_title('Overfitting Analysis')\n",
    "ax3.set_xticks(x_pos)\n",
    "ax3.set_xticklabels(comparison_df['Model'], rotation=45)\n",
    "ax3.grid(True, alpha=0.3)\n",
    "ax3.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Cross-Validation RMSE with error bars\n",
    "ax4 = axes[1, 1]\n",
    "ax4.bar(x_pos, comparison_df['CV_RMSE'], alpha=0.7, color='lightgreen',\n",
    "        yerr=comparison_df['CV_RMSE_Std'], capsize=5)\n",
    "ax4.set_xlabel('Models')\n",
    "ax4.set_ylabel('CV RMSE')\n",
    "ax4.set_title('Cross-Validation RMSE')\n",
    "ax4.set_xticks(x_pos)\n",
    "ax4.set_xticklabels(comparison_df['Model'], rotation=45)\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ANALYZING FEATURE IMPORTANCE\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "This StandardScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-8c974756a13f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mX_test_prepared\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrobust_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'LinearRegression'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Ridge'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Lasso'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ElasticNet'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mX_test_prepared\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# XGBoost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mX_test_prepared\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/local/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m    968\u001b[0m             \u001b[0mTransformed\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m         \"\"\"\n\u001b[0;32m--> 970\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m         \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/local/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfitted\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1222\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This StandardScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"üîç ANALYZING FEATURE IMPORTANCE\")\n",
    "\n",
    "# Function to get feature importance\n",
    "def get_feature_importance(model, model_name, X_test, y_test):\n",
    "    \"\"\"Get feature importance according to model type\"\"\"\n",
    "    \n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        # Models with feature_importances_ (XGBoost, RandomForest, etc.)\n",
    "        importance = model.feature_importances_\n",
    "        method = 'Built-in Feature Importance'\n",
    "    \n",
    "    elif hasattr(model, 'coef_'):\n",
    "        # Linear models\n",
    "        importance = np.abs(model.coef_)\n",
    "        method = 'Absolute Coefficients'\n",
    "    \n",
    "    else:\n",
    "        # Use permutation importance for other models\n",
    "        perm_importance = permutation_importance(\n",
    "            model, X_test, y_test, \n",
    "            n_repeats=10, random_state=42, \n",
    "            scoring='neg_mean_squared_error'\n",
    "        )\n",
    "        importance = perm_importance.importances_mean\n",
    "        method = 'Permutation Importance'\n",
    "    \n",
    "    return importance, method\n",
    "\n",
    "# Analyze importance for top 3 models\n",
    "top_3_models = comparison_df.head(3)\n",
    "importance_results = {}\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "for i, (_, row) in enumerate(top_3_models.iterrows()):\n",
    "    model_name = row['Model']\n",
    "    model_obj = all_results[model_name]['model']\n",
    "    \n",
    "    # Prepare test data according to model\n",
    "    if model_name.startswith('SVR'):\n",
    "        X_test_prepared = robust_scaler.transform(X_test)\n",
    "    elif model_name in ['LinearRegression', 'Ridge', 'Lasso', 'ElasticNet']:\n",
    "        X_test_prepared = scaler.transform(X_test)\n",
    "    else:  # XGBoost\n",
    "        X_test_prepared = X_test\n",
    "    \n",
    "    importance, method = get_feature_importance(model_obj, model_name, X_test_prepared, y_test)\n",
    "    \n",
    "    # Normalize importance\n",
    "    importance_normalized = importance / importance.sum()\n",
    "    \n",
    "    # Create DataFrame for visualization\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': feature_cols,\n",
    "        'Importance': importance_normalized\n",
    "    }).sort_values('Importance', ascending=True)\n",
    "    \n",
    "    importance_results[model_name] = importance_df\n",
    "    \n",
    "    # Plot\n",
    "    ax = axes[i]\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(importance_df)))\n",
    "    bars = ax.barh(importance_df['Feature'], importance_df['Importance'], color=colors)\n",
    "    ax.set_title(f'{model_name}\\n({method})')\n",
    "    ax.set_xlabel('Normalized Importance')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add values on bars\n",
    "    for bar, importance in zip(bars, importance_df['Importance']):\n",
    "        ax.text(bar.get_width() + 0.005, bar.get_y() + bar.get_height()/2, \n",
    "                f'{importance:.3f}', ha='left', va='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print feature importance ranking\n",
    "print(\"\\n=== FEATURE IMPORTANCE RANKING ===\")\n",
    "for model_name, imp_df in importance_results.items():\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    for i, (_, row) in enumerate(imp_df.sort_values('Importance', ascending=False).iterrows(), 1):\n",
    "        print(f\"  {i}. {row['Feature']}: {row['Importance']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Residual Analysis of Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select best model for detailed analysis\n",
    "best_model_results = all_results[best_model_name]\n",
    "best_model = best_model_results['model']\n",
    "y_train_pred = best_model_results['predictions']['train']\n",
    "y_test_pred = best_model_results['predictions']['test']\n",
    "\n",
    "print(f\"üîç RESIDUAL ANALYSIS - {best_model_name}\")\n",
    "\n",
    "# Calculate residuals\n",
    "train_residuals = y_train - y_train_pred\n",
    "test_residuals = y_test - y_test_pred\n",
    "\n",
    "# Create residual analysis plots\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# 1. Predictions vs Actual Values (Train)\n",
    "ax1 = axes[0, 0]\n",
    "ax1.scatter(y_train, y_train_pred, alpha=0.6, s=20)\n",
    "min_val = min(y_train.min(), y_train_pred.min())\n",
    "max_val = max(y_train.max(), y_train_pred.max())\n",
    "ax1.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2)\n",
    "ax1.set_xlabel('Actual Values')\n",
    "ax1.set_ylabel('Predictions')\n",
    "ax1.set_title('Train: Predictions vs Actual')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Predictions vs Actual Values (Test)\n",
    "ax2 = axes[0, 1]\n",
    "ax2.scatter(y_test, y_test_pred, alpha=0.6, s=20, color='orange')\n",
    "min_val = min(y_test.min(), y_test_pred.min())\n",
    "max_val = max(y_test.max(), y_test_pred.max())\n",
    "ax2.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2)\n",
    "ax2.set_xlabel('Actual Values')\n",
    "ax2.set_ylabel('Predictions')\n",
    "ax2.set_title('Test: Predictions vs Actual')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Residuals vs Predictions (Test)\n",
    "ax3 = axes[0, 2]\n",
    "ax3.scatter(y_test_pred, test_residuals, alpha=0.6, s=20, color='green')\n",
    "ax3.axhline(y=0, color='r', linestyle='--')\n",
    "ax3.set_xlabel('Predictions')\n",
    "ax3.set_ylabel('Residuals')\n",
    "ax3.set_title('Residuals vs Predictions (Test)')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Histogram of Residuals (Train)\n",
    "ax4 = axes[1, 0]\n",
    "ax4.hist(train_residuals, bins=30, alpha=0.7, density=True, color='skyblue')\n",
    "ax4.axvline(train_residuals.mean(), color='red', linestyle='--', label=f'Mean: {train_residuals.mean():.3f}')\n",
    "ax4.set_xlabel('Residuals')\n",
    "ax4.set_ylabel('Density')\n",
    "ax4.set_title('Residual Distribution (Train)')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "# 5. Histogram of Residuals (Test)\n",
    "ax5 = axes[1, 1]\n",
    "ax5.hist(test_residuals, bins=30, alpha=0.7, density=True, color='orange')\n",
    "ax5.axvline(test_residuals.mean(), color='red', linestyle='--', label=f'Mean: {test_residuals.mean():.3f}')\n",
    "ax5.set_xlabel('Residuals')\n",
    "ax5.set_ylabel('Density')\n",
    "ax5.set_title('Residual Distribution (Test)')\n",
    "ax5.legend()\n",
    "ax5.grid(True, alpha=0.3)\n",
    "\n",
    "# 6. Q-Q Plot of Residuals (Test)\n",
    "ax6 = axes[1, 2]\n",
    "stats.probplot(test_residuals, dist=\"norm\", plot=ax6)\n",
    "ax6.set_title('Q-Q Plot of Residuals (Test)')\n",
    "ax6.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Residual statistics\n",
    "print(f\"\\n=== RESIDUAL STATISTICS ===\")\n",
    "print(f\"Train:\")\n",
    "print(f\"  Mean: {train_residuals.mean():.6f}\")\n",
    "print(f\"  Std: {train_residuals.std():.4f}\")\n",
    "print(f\"  Skewness: {stats.skew(train_residuals):.4f}\")\n",
    "print(f\"  Kurtosis: {stats.kurtosis(train_residuals):.4f}\")\n",
    "\n",
    "print(f\"\\nTest:\")\n",
    "print(f\"  Mean: {test_residuals.mean():.6f}\")\n",
    "print(f\"  Std: {test_residuals.std():.4f}\")\n",
    "print(f\"  Skewness: {stats.skew(test_residuals):.4f}\")\n",
    "print(f\"  Kurtosis: {stats.kurtosis(test_residuals):.4f}\")\n",
    "\n",
    "# Normality test for residuals\n",
    "_, p_value = stats.shapiro(test_residuals[:1000] if len(test_residuals) > 1000 else test_residuals)\n",
    "print(f\"\\nNormality Test (Shapiro-Wilk): p-value = {p_value:.6f}\")\n",
    "print(f\"Residuals are normal: {'Yes' if p_value > 0.05 else 'No'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Learning and Validation Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "print(f\"üîç GENERATING LEARNING CURVES FOR {best_model_name}\")\n",
    "\n",
    "# Prepare data according to best model\n",
    "if best_model_name.startswith('SVR'):\n",
    "    X_for_curves = robust_scaler.fit_transform(X_train)\n",
    "elif best_model_name in ['LinearRegression', 'Ridge', 'Lasso', 'ElasticNet']:\n",
    "    X_for_curves = scaler.fit_transform(X_train)\n",
    "else:  # XGBoost\n",
    "    X_for_curves = X_train\n",
    "\n",
    "# Generate learning curves\n",
    "train_sizes, train_scores, val_scores = learning_curve(\n",
    "    best_model, X_for_curves, y_train,\n",
    "    cv=5, n_jobs=-1,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "    scoring='neg_mean_squared_error'\n",
    ")\n",
    "\n",
    "# Convert to RMSE\n",
    "train_rmse = np.sqrt(-train_scores)\n",
    "val_rmse = np.sqrt(-val_scores)\n",
    "\n",
    "# Calculate means and standard deviations\n",
    "train_rmse_mean = train_rmse.mean(axis=1)\n",
    "train_rmse_std = train_rmse.std(axis=1)\n",
    "val_rmse_mean = val_rmse.mean(axis=1)\n",
    "val_rmse_std = val_rmse.std(axis=1)\n",
    "\n",
    "# Learning curves plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(train_sizes, train_rmse_mean, 'o-', color='blue', label='Training RMSE')\n",
    "plt.fill_between(train_sizes, train_rmse_mean - train_rmse_std, \n",
    "                 train_rmse_mean + train_rmse_std, alpha=0.1, color='blue')\n",
    "\n",
    "plt.plot(train_sizes, val_rmse_mean, 'o-', color='red', label='Validation RMSE')\n",
    "plt.fill_between(train_sizes, val_rmse_mean - val_rmse_std, \n",
    "                 val_rmse_mean + val_rmse_std, alpha=0.1, color='red')\n",
    "\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title(f'Learning Curves - {best_model_name}')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Learning curves analysis\n",
    "final_gap = val_rmse_mean[-1] - train_rmse_mean[-1]\n",
    "print(f\"\\n=== LEARNING CURVES ANALYSIS ===\")\n",
    "print(f\"Final training RMSE: {train_rmse_mean[-1]:.4f} (¬±{train_rmse_std[-1]:.4f})\")\n",
    "print(f\"Final validation RMSE: {val_rmse_mean[-1]:.4f} (¬±{val_rmse_std[-1]:.4f})\")\n",
    "print(f\"Final gap (Val - Train): {final_gap:.4f}\")\n",
    "\n",
    "if final_gap > 0.1 * train_rmse_mean[-1]:\n",
    "    print(\"‚ö†Ô∏è Possible overfitting detected\")\n",
    "elif final_gap < 0:\n",
    "    print(\"‚ö†Ô∏è Possible underfitting or easier validation data\")\n",
    "else:\n",
    "    print(\"‚úÖ Good balance between bias and variance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Weight Optimization to Maximize Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize, differential_evolution\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "print(\"üéØ WEIGHT OPTIMIZATION TO MAXIMIZE OUTPUT\")\n",
    "\n",
    "# Objective function to maximize model prediction\n",
    "def objective_function(weights, model, scaler=None, feature_names=None):\n",
    "    \"\"\"Objective function: we want to maximize model output\"\"\"\n",
    "    weights_reshaped = weights.reshape(1, -1)\n",
    "    \n",
    "    # Apply scaling if necessary\n",
    "    if scaler is not None:\n",
    "        weights_scaled = scaler.transform(weights_reshaped)\n",
    "    else:\n",
    "        weights_scaled = weights_reshaped\n",
    "    \n",
    "    # Predict (we want to maximize, so return negative)\n",
    "    prediction = model.predict(weights_scaled)[0]\n",
    "    return -prediction  # Negative because minimize searches for minimum\n",
    "\n",
    "# Define feature bounds based on data\n",
    "feature_bounds = []\n",
    "print(\"\\nFeature bounds based on data:\")\n",
    "for i, feature in enumerate(feature_cols):\n",
    "    min_val = X[feature].min()\n",
    "    max_val = X[feature].max()\n",
    "    feature_bounds.append((min_val, max_val))\n",
    "    print(f\"  {feature}: [{min_val:.2f}, {max_val:.2f}]\")\n",
    "\n",
    "# Optimize for best model\n",
    "print(f\"\\nüîß Optimizing with {best_model_name}...\")\n",
    "\n",
    "# Prepare scaler if necessary\n",
    "optimization_scaler = None\n",
    "if best_model_name.startswith('SVR'):\n",
    "    optimization_scaler = RobustScaler().fit(X_train)\n",
    "elif best_model_name in ['LinearRegression', 'Ridge', 'Lasso', 'ElasticNet']:\n",
    "    optimization_scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "# Use differential evolution (more robust for non-convex problems)\n",
    "result = differential_evolution(\n",
    "    objective_function,\n",
    "    feature_bounds,\n",
    "    args=(best_model, optimization_scaler, feature_cols),\n",
    "    seed=42,\n",
    "    maxiter=1000,\n",
    "    popsize=15\n",
    ")\n",
    "\n",
    "optimal_weights = result.x\n",
    "optimal_prediction = -result.fun  # Convert back (remove negative)\n",
    "\n",
    "print(f\"\\n‚úÖ OPTIMIZATION COMPLETED\")\n",
    "print(f\"Maximum predicted value: {optimal_prediction:.4f}\")\n",
    "print(f\"Number of evaluations: {result.nfev}\")\n",
    "print(f\"Success: {result.success}\")\n",
    "\n",
    "# Show optimal weights\n",
    "print(f\"\\n=== OPTIMAL WEIGHTS TO MAXIMIZE OUTPUT ===\")\n",
    "optimal_df = pd.DataFrame({\n",
    "    'Feature': feature_cols,\n",
    "    'Optimal_Value': optimal_weights,\n",
    "    'Data_Min': [X[col].min() for col in feature_cols],\n",
    "    'Data_Max': [X[col].max() for col in feature_cols],\n",
    "    'Percentile_in_Data': [stats.percentileofscore(X[col], val) for col, val in zip(feature_cols, optimal_weights)]\n",
    "})\n",
    "\n",
    "display(optimal_df.round(4))\n",
    "\n",
    "# Compare with existing dataset examples\n",
    "print(f\"\\n=== COMPARISON WITH EXISTING DATA ===\")\n",
    "# Find top 5 samples with highest target values\n",
    "top_5_indices = y.nlargest(5).index\n",
    "top_5_predictions = []\n",
    "\n",
    "for idx in top_5_indices:\n",
    "    sample = X.loc[idx].values.reshape(1, -1)\n",
    "    if optimization_scaler is not None:\n",
    "        sample_scaled = optimization_scaler.transform(sample)\n",
    "    else:\n",
    "        sample_scaled = sample\n",
    "    pred = best_model.predict(sample_scaled)[0]\n",
    "    top_5_predictions.append(pred)\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Type': ['Dataset Top 1', 'Dataset Top 2', 'Dataset Top 3', 'Dataset Top 4', 'Dataset Top 5', 'OPTIMAL WEIGHTS'],\n",
    "    'Prediction': top_5_predictions + [optimal_prediction],\n",
    "    'Actual_Target': list(y.loc[top_5_indices]) + ['N/A']\n",
    "})\n",
    "\n",
    "display(comparison_df.round(4))\n",
    "\n",
    "improvement = optimal_prediction - max(top_5_predictions)\n",
    "print(f\"\\nImprovement over best dataset case: {improvement:.4f} ({improvement/max(top_5_predictions)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Optimal Weights Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal weights visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Optimal values vs data ranges\n",
    "ax1 = axes[0, 0]\n",
    "x_pos = np.arange(len(feature_cols))\n",
    "ax1.bar(x_pos, optimal_weights, alpha=0.7, color='gold', label='Optimal Values')\n",
    "\n",
    "# Add lines for min/max of data\n",
    "mins = [X[col].min() for col in feature_cols]\n",
    "maxs = [X[col].max() for col in feature_cols]\n",
    "ax1.errorbar(x_pos, optimal_weights, \n",
    "            yerr=[np.array(optimal_weights) - np.array(mins), \n",
    "                  np.array(maxs) - np.array(optimal_weights)], \n",
    "            fmt='none', color='red', alpha=0.5, capsize=5)\n",
    "\n",
    "ax1.set_xlabel('Features')\n",
    "ax1.set_ylabel('Values')\n",
    "ax1.set_title('Optimal Values vs Data Ranges')\n",
    "ax1.set_xticks(x_pos)\n",
    "ax1.set_xticklabels(feature_cols, rotation=45)\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Percentiles of optimal values\n",
    "ax2 = axes[0, 1]\n",
    "percentiles = optimal_df['Percentile_in_Data']\n",
    "colors = ['red' if p > 90 else 'orange' if p > 75 else 'yellow' if p > 50 else 'lightblue' for p in percentiles]\n",
    "bars = ax2.bar(x_pos, percentiles, color=colors, alpha=0.7)\n",
    "ax2.axhline(y=50, color='gray', linestyle='--', alpha=0.7, label='Median')\n",
    "ax2.axhline(y=90, color='red', linestyle='--', alpha=0.7, label='90th Percentile')\n",
    "ax2.set_xlabel('Features')\n",
    "ax2.set_ylabel('Percentile')\n",
    "ax2.set_title('Percentiles of Optimal Values')\n",
    "ax2.set_xticks(x_pos)\n",
    "ax2.set_xticklabels(feature_cols, rotation=45)\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Add labels with percentiles\n",
    "for bar, p in zip(bars, percentiles):\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n",
    "            f'{p:.0f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# 3. Comparison with best dataset samples\n",
    "ax3 = axes[1, 0]\n",
    "comparison_values = list(comparison_df['Prediction'][:-1]) + [optimal_prediction]\n",
    "labels = ['Top 1', 'Top 2', 'Top 3', 'Top 4', 'Top 5', 'Optimal']\n",
    "colors = ['lightblue'] * 5 + ['gold']\n",
    "\n",
    "bars = ax3.bar(labels, comparison_values, color=colors, alpha=0.7)\n",
    "ax3.set_xlabel('Samples')\n",
    "ax3.set_ylabel('Prediction')\n",
    "ax3.set_title('Comparison: Best Samples vs Optimal')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Add labels with values\n",
    "for bar, val in zip(bars, comparison_values):\n",
    "    ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(comparison_values)*0.01, \n",
    "            f'{val:.2f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# 4. Radar chart comparing optimal vs dataset average\n",
    "ax4 = axes[1, 1]\n",
    "angles = np.linspace(0, 2*np.pi, len(feature_cols), endpoint=False).tolist()\n",
    "angles += angles[:1]  # Complete the circle\n",
    "\n",
    "# Normalize values for radar chart\n",
    "scaler_radar = MinMaxScaler()\n",
    "data_for_radar = np.column_stack([optimal_weights, X[feature_cols].mean().values])\n",
    "normalized_data = scaler_radar.fit_transform(data_for_radar)\n",
    "\n",
    "optimal_normalized = normalized_data[:, 0].tolist()\n",
    "mean_normalized = normalized_data[:, 1].tolist()\n",
    "\n",
    "optimal_normalized += optimal_normalized[:1]\n",
    "mean_normalized += mean_normalized[:1]\n",
    "\n",
    "ax4 = plt.subplot(2, 2, 4, projection='polar')\n",
    "ax4.plot(angles, optimal_normalized, 'o-', linewidth=2, label='Optimal Values', color='gold')\n",
    "ax4.fill(angles, optimal_normalized, alpha=0.25, color='gold')\n",
    "ax4.plot(angles, mean_normalized, 'o-', linewidth=2, label='Dataset Average', color='blue')\n",
    "ax4.fill(angles, mean_normalized, alpha=0.25, color='blue')\n",
    "\n",
    "ax4.set_xticks(angles[:-1])\n",
    "ax4.set_xticklabels(feature_cols)\n",
    "ax4.set_ylim(0, 1)\n",
    "ax4.set_title('Radar Comparison: Optimal vs Average', y=1.08)\n",
    "ax4.legend(loc='upper right', bbox_to_anchor=(1.2, 1.0))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Final Summary and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"üéØ MACHINE LEARNING PROJECT FINAL SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nüìä DATASET:\")\n",
    "print(f\"   ‚Ä¢ Size: {X.shape[0]} samples, {X.shape[1]} features\")\n",
    "print(f\"   ‚Ä¢ Features: {', '.join(feature_cols)}\")\n",
    "print(f\"   ‚Ä¢ Split: {X_train.shape[0]} train / {X_test.shape[0]} test\")\n",
    "\n",
    "print(f\"\\nü§ñ MODELS EVALUATED:\")\n",
    "models_tested = len(all_results)\n",
    "print(f\"   ‚Ä¢ Total models: {models_tested}\")\n",
    "print(f\"   ‚Ä¢ Linear Regression: {len(linear_results)} variants\")\n",
    "print(f\"   ‚Ä¢ Support Vector Regression: {len(svr_results)} kernels\")\n",
    "print(f\"   ‚Ä¢ XGBoost: 1 model with optimized hyperparameters\")\n",
    "\n",
    "print(f\"\\nüèÜ BEST MODEL: {best_model_name}\")\n",
    "best_test_metrics = best_model_results['test_metrics']\n",
    "print(f\"   ‚Ä¢ R¬≤ Score: {best_test_metrics['R¬≤']:.4f}\")\n",
    "print(f\"   ‚Ä¢ RMSE: {best_test_metrics['RMSE']:.4f}\")\n",
    "print(f\"   ‚Ä¢ MAE: {best_test_metrics['MAE']:.4f}\")\n",
    "print(f\"   ‚Ä¢ MAPE: {best_test_metrics['MAPE']:.2f}%\")\n",
    "print(f\"   ‚Ä¢ CV RMSE: {best_model_results['cv_rmse']:.4f} (¬±{best_model_results['cv_rmse_std']:.4f})\")\n",
    "\n",
    "print(f\"\\nüéØ MOST IMPORTANT FEATURES:\")\n",
    "if best_model_name in importance_results:\n",
    "    top_features = importance_results[best_model_name].sort_values('Importance', ascending=False).head(3)\n",
    "    for i, (_, row) in enumerate(top_features.iterrows(), 1):\n",
    "        print(f\"   {i}. {row['Feature']}: {row['Importance']:.4f}\")\n",
    "\n",
    "print(f\"\\n‚ö° OPTIMAL WEIGHTS FOR MAXIMIZATION:\")\n",
    "print(f\"   ‚Ä¢ Maximum predicted value: {optimal_prediction:.4f}\")\n",
    "print(f\"   ‚Ä¢ Improvement over best sample: {improvement:.4f} ({improvement/max(top_5_predictions)*100:.2f}%)\")\n",
    "print(f\"   ‚Ä¢ Features to maximize:\")\n",
    "high_percentile_features = optimal_df[optimal_df['Percentile_in_Data'] > 75]\n",
    "for _, row in high_percentile_features.iterrows():\n",
    "    print(f\"     - {row['Feature']}: {row['Optimal_Value']:.2f} (percentile {row['Percentile_in_Data']:.0f})\")\n",
    "\n",
    "print(f\"\\nüìà MODEL QUALITY ANALYSIS:\")\n",
    "overfitting_score = best_model_results['train_metrics']['RMSE'] - best_model_results['test_metrics']['RMSE']\n",
    "if abs(overfitting_score) < 0.1 * best_model_results['test_metrics']['RMSE']:\n",
    "    print(f\"   ‚Ä¢ ‚úÖ Good balance between bias and variance\")\n",
    "elif overfitting_score > 0:\n",
    "    print(f\"   ‚Ä¢ ‚ö†Ô∏è Slight overfitting detected (difference: {overfitting_score:.4f})\")\n",
    "else:\n",
    "    print(f\"   ‚Ä¢ ‚ö†Ô∏è Possible underfitting\")\n",
    "\n",
    "if best_test_metrics['R¬≤'] > 0.8:\n",
    "    quality = \"Excellent\"\n",
    "elif best_test_metrics['R¬≤'] > 0.6:\n",
    "    quality = \"Good\"\n",
    "elif best_test_metrics['R¬≤'] > 0.4:\n",
    "    quality = \"Fair\"\n",
    "else:\n",
    "    quality = \"Needs improvement\"\n",
    "    \n",
    "print(f\"   ‚Ä¢ Fit quality: {quality} (R¬≤ = {best_test_metrics['R¬≤']:.4f})\")\n",
    "\n",
    "print(f\"\\nüî¨ RECOMMENDATIONS:\")\n",
    "print(f\"   ‚Ä¢ To maximize output, use the optimal weights found\")\n",
    "print(f\"   ‚Ä¢ Focus on the highest importance features identified\")\n",
    "\n",
    "if best_test_metrics['R¬≤'] < 0.8:\n",
    "    print(f\"   ‚Ä¢ Consider additional feature engineering to improve R¬≤\")\n",
    "    print(f\"   ‚Ä¢ Explore more complex models (Neural Networks, Ensemble methods)\")\n",
    "    \n",
    "if abs(overfitting_score) > 0.1 * best_model_results['test_metrics']['RMSE']:\n",
    "    print(f\"   ‚Ä¢ Consider additional regularization techniques\")\n",
    "    print(f\"   ‚Ä¢ Increase training dataset size if possible\")\n",
    "\n",
    "print(f\"   ‚Ä¢ Use cross-validation for production decisions\")\n",
    "print(f\"   ‚Ä¢ Monitor model performance on new data\")\n",
    "\n",
    "print(f\"\\nüíæ FILES GENERATED:\")\n",
    "print(f\"   ‚Ä¢ 01_exploratory_data_analysis_EN.ipynb: Complete exploratory analysis\")\n",
    "print(f\"   ‚Ä¢ 02_model_training_evaluation_EN.ipynb: Model training and evaluation\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚ú® PROJECT COMPLETED SUCCESSFULLY ‚ú®\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
